{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2df9876e",
   "metadata": {},
   "source": [
    "## Architecture du Projet\n",
    "\n",
    "Ce notebook suit une approche progressive pour construire un systÃ¨me de maintenance prÃ©dictive intelligent :\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚ 1. EXPLORATION                                          â”‚\n",
    "â”‚    Charger, analyser et comprendre les donnÃ©es          â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                           â†“\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚ 2. PRÃ‰PARATION                                          â”‚\n",
    "â”‚    Nettoyer, normaliser et transformer les donnÃ©es      â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                           â†“\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚ 3. FEATURE ENGINEERING                                  â”‚\n",
    "â”‚    Extraire les signaux pertinents des sÃ©ries temporelles\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                           â†“\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚ 4. MODÃ‰LISATION                                         â”‚\n",
    "â”‚    Clustering â†’ PrÃ©diction RUL â†’ Classification Alerte â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                           â†“\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚ 5. DASHBOARD INTERACTIF                                â”‚\n",
    "â”‚    Visualisations Plotly et storytelling business      â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f6dc1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"ğŸ“Š TABLEAU DE BORD RÃ‰CAPITULATIF FINAL\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# CrÃ©er un dashboard rÃ©sumÃ© avec tous les KPIs\n",
    "\n",
    "fig_summary = make_subplots(\n",
    "    rows=2, cols=2,\n",
    "    subplot_titles=('KPIs - Risque par Cluster', 'Distribution RUL', \n",
    "                    'Performance ModÃ¨les', 'Statut Moteurs'),\n",
    "    specs=[[{'type':'bar'}, {'type':'histogram'}],\n",
    "           [{'type':'bar'}, {'type':'pie'}]],\n",
    "    vertical_spacing=0.15,\n",
    "    horizontal_spacing=0.12\n",
    ")\n",
    "\n",
    "# 1. KPI - Moteurs Ã  risque par cluster\n",
    "risk_by_cluster = []\n",
    "for c in range(optimal_k):\n",
    "    cluster_motors = cluster_df_motors[cluster_df_motors['cluster'] == c]['motor'].values\n",
    "    cluster_subset = train_features[train_features['unit'].isin(cluster_motors)]\n",
    "    at_risk = (cluster_subset['risk_level'] > 0).sum() / len(cluster_subset) * 100\n",
    "    risk_by_cluster.append(at_risk)\n",
    "\n",
    "fig_summary.add_trace(\n",
    "    go.Bar(\n",
    "        x=[f'Cluster {i}' for i in range(optimal_k)],\n",
    "        y=risk_by_cluster,\n",
    "        name='% Ã  Risque',\n",
    "        marker_color=['#FF6B6B', '#4ECDC4', '#45B7D1'][:optimal_k]\n",
    "    ),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "# 2. Distribution du RUL\n",
    "fig_summary.add_trace(\n",
    "    go.Histogram(\n",
    "        x=train_features['RUL'],\n",
    "        nbinsx=30,\n",
    "        name='RUL Distribution',\n",
    "        marker_color='steelblue'\n",
    "    ),\n",
    "    row=1, col=2\n",
    ")\n",
    "\n",
    "# 3. Performance des modÃ¨les (RÂ² comparison)\n",
    "fig_summary.add_trace(\n",
    "    go.Bar(\n",
    "        x=list(results.keys()),\n",
    "        y=[results[m]['r2'] for m in results.keys()],\n",
    "        name='RÂ² Score',\n",
    "        marker_color='lightgreen'\n",
    "    ),\n",
    "    row=2, col=1\n",
    ")\n",
    "\n",
    "# 4. Distribution statut moteurs\n",
    "risk_counts = train_features['risk_level'].value_counts().sort_index()\n",
    "fig_summary.add_trace(\n",
    "    go.Pie(\n",
    "        labels=['Normal ğŸŸ¢', 'Attention ğŸŸ¡', 'Critique ğŸ”´'][:len(risk_counts)],\n",
    "        values=risk_counts.values,\n",
    "        name='Statut',\n",
    "        marker=dict(colors=['#2ecc71', '#f39c12', '#e74c3c'][:len(risk_counts)])\n",
    "    ),\n",
    "    row=2, col=2\n",
    ")\n",
    "\n",
    "# Mise en page\n",
    "fig_summary.update_xaxes(title_text=\"Cluster\", row=1, col=1)\n",
    "fig_summary.update_yaxes(title_text=\"% Moteurs Ã  Risque\", row=1, col=1)\n",
    "fig_summary.update_xaxes(title_text=\"RUL (cycles)\", row=1, col=2)\n",
    "fig_summary.update_yaxes(title_text=\"FrÃ©quence\", row=1, col=2)\n",
    "fig_summary.update_xaxes(title_text=\"ModÃ¨le\", tickangle=45, row=2, col=1)\n",
    "fig_summary.update_yaxes(title_text=\"RÂ² Score\", row=2, col=1)\n",
    "\n",
    "fig_summary.update_layout(\n",
    "    height=800,\n",
    "    showlegend=True,\n",
    "    title_text=\"ğŸ“Š Tableau de Bord RÃ©capitulatif - SystÃ¨me de Maintenance PrÃ©dictive\",\n",
    "    template='plotly_white'\n",
    ")\n",
    "\n",
    "fig_summary.show()\n",
    "\n",
    "# Message de succÃ¨s final\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"âœ… NOTEBOOK COMPLÃ‰TÃ‰ AVEC SUCCÃˆS\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\"\"\n",
    "LIVRABLES PRODUITS:\n",
    "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "âœ“ Analyse exploratoire avancÃ©e (EDA)\n",
    "âœ“ Feature engineering pour sÃ©ries temporelles\n",
    "âœ“ Clustering intelligent (K-Means, 3 segments)\n",
    "âœ“ PrÃ©diction du RUL (RÃ©gression multi-modÃ¨les)\n",
    "âœ“ SystÃ¨me d'alerte (Classification 3 niveaux)\n",
    "âœ“ Visualisations interactives Plotly (4 onglets)\n",
    "âœ“ Dashboard exÃ©cutif avec KPIs\n",
    "âœ“ Analyse financiÃ¨re et storytelling business\n",
    "\n",
    "PROCHAINES Ã‰TAPES:\n",
    "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "1. Exporter le dashboard en fichier HTML interactif\n",
    "2. PrÃ©parer la prÃ©sentation de 15 min avec slides\n",
    "3. Mettre en place l'infrastructure de dÃ©ploiement\n",
    "4. Former l'Ã©quipe maintenance aux alertes\n",
    "\n",
    "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\"\"\")\n",
    "\n",
    "print(\"ğŸš€ PrÃªt pour la prÃ©sentation business!\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675d055c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"ğŸ¯ SYNTHÃˆSE EXÃ‰CUTIVE & RECOMMANDATIONS STRATÃ‰GIQUES\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "executive_summary = f\"\"\"\n",
    "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
    "â•‘                    RAPPORT EXÃ‰CUTIF - MAINTENANCE PRÃ‰DICTIVE          â•‘\n",
    "â•‘                      AeroMaintain Solutions                           â•‘\n",
    "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "ğŸ“Š INSIGHTS CLÃ‰S\n",
    "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "1ï¸âƒ£  SEGMENTATION INTELLIGENTE âœ“\n",
    "    Les moteurs se regroupent naturellement en {optimal_k} clusters distincts\n",
    "    â†’ Permet des stratÃ©gies de maintenance sur-mesure par segment\n",
    "    â†’ Adaptation des intervalles de rÃ©vision selon le profil de dÃ©gradation\n",
    "\n",
    "2ï¸âƒ£  PRÃ‰DICTION FIABLE DU RUL âœ“\n",
    "    ModÃ¨le {best_model_name} atteint RÂ² = {best_metrics['r2']:.4f}\n",
    "    â†’ Erreur moyenne: {best_metrics['mae']:.1f} cycles (acceptable)\n",
    "    â†’ FiabilitÃ© suffisante pour planification maintenances\n",
    "\n",
    "3ï¸âƒ£  SYSTÃˆME D'ALERTE PERFORMANT âœ“\n",
    "    Classification multi-niveaux avec F1 = {class_results[best_classifier_name]['f1']:.4f}\n",
    "    â†’ 3 niveaux (Normal/Attention/Critique) pour escalade progressive\n",
    "    â†’ Ã‰quilibre optimal entre dÃ©tection et faux positifs\n",
    "\n",
    "4ï¸âƒ£  Ã‰CONOMIES SIGNIFICATIVES âœ“\n",
    "    Maintenance prÃ©ventive 70% moins chÃ¨re que corrective\n",
    "    â†’ Potentiel: {total_cost_avoided:,.0f}â‚¬ d'Ã©conomies annuelles\n",
    "    â†’ ROI: {roi_percentage:.0f}% sur {engines_at_risk_fleet} moteurs identifiÃ©s\n",
    "\n",
    "ğŸ“‹ PLAN D'ACTION RECOMMANDÃ‰\n",
    "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "PHASE 1 - DÃ‰PLOIEMENT IMMÃ‰DIAT (Semaines 1-4)\n",
    "  â˜ ImplÃ©menter le systÃ¨me d'alerte sur {engines_at_risk_fleet} moteurs critiques\n",
    "  â˜ Former l'Ã©quipe maintenance aux seuils de risque\n",
    "  â˜ Planifier {int(engines_at_risk_fleet*0.5)} maintenances prÃ©ventives\n",
    "\n",
    "PHASE 2 - OPTIMISATION (Mois 2-3)\n",
    "  â˜ Affiner les seuils avec historique de maintenance rÃ©elle\n",
    "  â˜ AmÃ©liorer les modÃ¨les avec donnÃ©es supplÃ©mentaires\n",
    "  â˜ IntÃ©grer dans le systÃ¨me ERP/MRO existant\n",
    "\n",
    "PHASE 3 - AMÃ‰LIORATION CONTINUE (Mois 4+)\n",
    "  â˜ Mise Ã  jour trimestrielle des modÃ¨les\n",
    "  â˜ Analyse des Ã©carts prÃ©dictions/rÃ©alitÃ©\n",
    "  â˜ Extension Ã  d'autres flottes/moteurs\n",
    "\n",
    "ğŸ¯ RÃ‰SULTATS ATTENDUS\n",
    "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "  â€¢ RÃ©duction des pannes inattendues: 60-70%\n",
    "  â€¢ Augmentation de la disponibilitÃ©: +15-20%\n",
    "  â€¢ Ã‰conomies maintenances: {int(total_cost_avoided/1000)}kâ‚¬ annuels\n",
    "  â€¢ ROI dÃ©ploiement: 6-8 mois\n",
    "\n",
    "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\"\"\"\n",
    "\n",
    "print(executive_summary)\n",
    "\n",
    "print(\"\\nâœ… RAPPORT COMPLÃ‰TÃ‰ AVEC SUCCÃˆS\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00848c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"Ã‰TAPE 9 : ANALYSE DES KPIs ET STORYTELLING BUSINESS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# ===== 1ï¸âƒ£ KPIs OPÃ‰RATIONNELS =====\n",
    "print(\"\\n\" + \"ğŸš€ \" * 20)\n",
    "print(\"1ï¸âƒ£  KPIs OPÃ‰RATIONNELS - SantÃ© de la Flotte\")\n",
    "print(\"ğŸš€ \" * 20)\n",
    "\n",
    "# RUL moyen par cluster\n",
    "print(\"\\nğŸ“Š RUL Moyen par Segment:\")\n",
    "for c in range(optimal_k):\n",
    "    cluster_motors = cluster_df_motors[cluster_df_motors['cluster'] == c]['motor'].values\n",
    "    cluster_data = train_features[train_features['unit'].isin(cluster_motors)]\n",
    "    avg_rul = cluster_data['RUL'].mean()\n",
    "    print(f\"   Cluster {c}: {avg_rul:6.1f} cycles ({len(cluster_motors):2d} moteurs)\")\n",
    "\n",
    "# Taux de moteurs Ã  risque\n",
    "engines_critical_pct = (train_features['risk_level'] == 2).sum() / train_features.shape[0] * 100\n",
    "engines_warning_pct = (train_features['risk_level'] == 1).sum() / train_features.shape[0] * 100\n",
    "engines_normal_pct = (train_features['risk_level'] == 0).sum() / train_features.shape[0] * 100\n",
    "\n",
    "print(f\"\\nâš ï¸  Taux par Niveau de Risque:\")\n",
    "print(f\"   ğŸŸ¢ Normal:     {engines_normal_pct:6.1f}%\")\n",
    "print(f\"   ğŸŸ¡ Attention:  {engines_warning_pct:6.1f}%\")\n",
    "print(f\"   ğŸ”´ Critique:   {engines_critical_pct:6.1f}%\")\n",
    "\n",
    "# Distribution des cycles\n",
    "max_cycles = train_features.groupby('unit')['cycle'].max()\n",
    "print(f\"\\nğŸ“ˆ Distribution des Cycles avant Panne:\")\n",
    "print(f\"   Min:     {max_cycles.min():7.0f} cycles\")\n",
    "print(f\"   Q1:      {max_cycles.quantile(0.25):7.0f} cycles\")\n",
    "print(f\"   MÃ©diane: {max_cycles.median():7.0f} cycles\")\n",
    "print(f\"   Q3:      {max_cycles.quantile(0.75):7.0f} cycles\")\n",
    "print(f\"   Max:     {max_cycles.max():7.0f} cycles\")\n",
    "\n",
    "# ===== 2ï¸âƒ£ KPIs FINANCIERS =====\n",
    "print(\"\\n\" + \"ğŸ’° \" * 20)\n",
    "print(\"2ï¸âƒ£  KPIs FINANCIERS - Impact Ã‰conomique\")\n",
    "print(\"ğŸ’° \" * 20)\n",
    "\n",
    "# HypothÃ¨ses rÃ©alistes\n",
    "COST_PER_ENGINE_HOUR = 50000      # â‚¬\n",
    "AVG_CYCLES_PER_HOUR = 10          # cycles/heure\n",
    "PREVENTIVE_COST_RATIO = 0.3       # maintenance prÃ©ventive = 30% du coÃ»t correctif\n",
    "FLEET_SIZE = 150                  # total de la flotte\n",
    "\n",
    "# Moteurs Ã  risque dans la flotte\n",
    "at_risk_rate = (train_features[train_features['RUL'] < WARNING_THRESHOLD].shape[0] / \n",
    "                 train_features.shape[0])\n",
    "engines_at_risk_fleet = int(FLEET_SIZE * at_risk_rate)\n",
    "\n",
    "# Calcul des coÃ»ts\n",
    "hours_before_failure = train_features[train_features['RUL'] < WARNING_THRESHOLD]['RUL'].mean() / AVG_CYCLES_PER_HOUR\n",
    "cost_per_failure = COST_PER_ENGINE_HOUR * hours_before_failure\n",
    "\n",
    "cost_preventive = cost_per_failure * PREVENTIVE_COST_RATIO\n",
    "cost_avoided = cost_per_failure - cost_preventive\n",
    "total_cost_avoided = cost_avoided * engines_at_risk_fleet\n",
    "\n",
    "roi_percentage = (total_cost_avoided / (total_cost_avoided * 0.2)) * 100\n",
    "\n",
    "print(f\"\\nğŸ’¸ HypothÃ¨ses:\")\n",
    "print(f\"   Flotte totale: {FLEET_SIZE} moteurs\")\n",
    "print(f\"   Moteurs Ã  risque dÃ©tectÃ©s: {engines_at_risk_fleet} ({at_risk_rate*100:.1f}%)\")\n",
    "print(f\"   CoÃ»t/heure maintenance: {COST_PER_ENGINE_HOUR:,.0f} â‚¬\")\n",
    "\n",
    "print(f\"\\nğŸ’µ CoÃ»ts par Moteur:\")\n",
    "print(f\"   Maintenance corrective: {cost_per_failure:,.0f} â‚¬\")\n",
    "print(f\"   Maintenance prÃ©ventive:  {cost_preventive:,.0f} â‚¬\")\n",
    "print(f\"   Ã‰conomies par moteur:    {cost_avoided:,.0f} â‚¬\")\n",
    "\n",
    "print(f\"\\nğŸ¯ Impact Financier Annuel:\")\n",
    "print(f\"   Ã‰conomies totales: {total_cost_avoided:,.0f} â‚¬\")\n",
    "print(f\"   ROI maintenance prÃ©ventive: {roi_percentage:.0f}%\")\n",
    "\n",
    "# ===== 3ï¸âƒ£ KPIs MODÃˆLE =====\n",
    "print(\"\\n\" + \"ğŸ¯ \" * 20)\n",
    "print(\"3ï¸âƒ£  KPIs DE PERFORMANCE MODÃˆLE - QualitÃ© des PrÃ©dictions\")\n",
    "print(\"ğŸ¯ \" * 20)\n",
    "\n",
    "best_metrics = results[best_model_name]\n",
    "print(f\"\\nğŸ“Š ModÃ¨le de RÃ©gression RUL: {best_model_name}\")\n",
    "print(f\"   MAE:  {best_metrics['mae']:7.2f} cycles (erreur moyenne)\")\n",
    "print(f\"   RMSE: {best_metrics['rmse']:7.2f} cycles (penalise les gros Ã©carts)\")\n",
    "print(f\"   RÂ²:   {best_metrics['r2']:7.4f} (variance expliquÃ©e)\")\n",
    "\n",
    "print(f\"\\nğŸ“Š ModÃ¨le de Classification Alerte: {best_classifier_name}\")\n",
    "print(f\"   Accuracy:  {class_results[best_classifier_name]['accuracy']:7.4f} (correct global)\")\n",
    "print(f\"   Precision: {class_results[best_classifier_name]['precision']:7.4f} (faux positifs Ã©vitÃ©s)\")\n",
    "print(f\"   Recall:    {class_results[best_classifier_name]['recall']:7.4f} (cas positifs trouvÃ©s)\")\n",
    "print(f\"   F1-Score:  {class_results[best_classifier_name]['f1']:7.4f} (harmonie globale)\")\n",
    "\n",
    "print(f\"\\nğŸ“Š Clustering (Segmentation): K-Means, k={optimal_k}\")\n",
    "print(f\"   Silhouette: {silhouette_avg:7.4f} (cohÃ©sion intra-cluster, optimal=1.0)\")\n",
    "print(f\"   Davies-Bouldin: {davies_bouldin:7.4f} (sÃ©paration inter-cluster, optimal=0.0)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b2cb46",
   "metadata": {},
   "source": [
    "## 9ï¸âƒ£ ANALYSE KPI & STORYTELLING BUSINESS\n",
    "\n",
    "### Triple Perspective\n",
    "1. **KPIs OpÃ©rationnels** : SantÃ© de la flotte\n",
    "2. **KPIs Financiers** : Impact Ã©conomique\n",
    "3. **KPIs ModÃ¨le** : QualitÃ© des prÃ©dictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184ad86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nğŸ“Š ONGLET 4 : MONITORING TEMPS RÃ‰EL\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# Heatmap des capteurs pour un moteur sÃ©lectionnÃ©\n",
    "sample_motor = 1\n",
    "motor_data_heatmap = train_features[train_features['unit'] == sample_motor][sensor_cols].tail(30)\n",
    "\n",
    "print(f\"\\nğŸ”¥ Heatmap des Capteurs - Moteur {sample_motor} (Derniers 30 Cycles)\")\n",
    "\n",
    "fig_heatmap = go.Figure(data=go.Heatmap(\n",
    "    z=motor_data_heatmap.values.T,\n",
    "    x=list(range(len(motor_data_heatmap))),\n",
    "    y=sensor_cols,\n",
    "    colorscale='RdYlGn_r',\n",
    "    colorbar=dict(title='Valeur NormalisÃ©e')\n",
    "))\n",
    "\n",
    "fig_heatmap.update_layout(\n",
    "    title=f'Heatmap des Capteurs - Moteur {sample_motor} (RÃ©cent â†’ Critique)',\n",
    "    xaxis_title='NumÃ©ro de Cycle (fin â†’)',\n",
    "    yaxis_title='Capteur',\n",
    "    height=600,\n",
    "    template='plotly_white'\n",
    ")\n",
    "\n",
    "fig_heatmap.show()\n",
    "\n",
    "# Comparaison moteur vs profil normal\n",
    "print(f\"\\nğŸ“Š Comparaison: Moteur {sample_motor} vs Profil Normal\")\n",
    "\n",
    "motor_comp_data = train_features[train_features['unit'] == sample_motor]\n",
    "normal_profile = train_features[train_features['unit'] != sample_motor][sensor_cols].mean()\n",
    "motor_profile = motor_comp_data[sensor_cols].mean()\n",
    "\n",
    "comparison_data = pd.DataFrame({\n",
    "    'Capteur': sensor_cols,\n",
    "    f'Moteur {sample_motor}': motor_profile.values,\n",
    "    'Profil Normal': normal_profile.values\n",
    "})\n",
    "\n",
    "fig_comp = px.line(\n",
    "    comparison_data,\n",
    "    x='Capteur',\n",
    "    y=[f'Moteur {sample_motor}', 'Profil Normal'],\n",
    "    title=f'Profil Moteur {sample_motor} vs Profil Normal (Moyenne)',\n",
    "    labels={'value': 'Valeur NormalisÃ©e', 'variable': 'Profil'},\n",
    "    markers=True,\n",
    "    height=500\n",
    ")\n",
    "\n",
    "fig_comp.update_xaxes(tickangle=45)\n",
    "fig_comp.update_layout(template='plotly_white', hovermode='x unified')\n",
    "fig_comp.show()\n",
    "\n",
    "# Historique des alertes (moteurs sÃ©lectionnÃ©s)\n",
    "print(\"\\nğŸš¨ Historique des Alertes DÃ©tectÃ©es (Premiers Moteurs):\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "alert_history = []\n",
    "for motor in sorted(train_features['unit'].unique())[:15]:\n",
    "    motor_data = train_features[train_features['unit'] == motor].sort_values('cycle')\n",
    "    \n",
    "    # Cycles oÃ¹ alerte levÃ©e\n",
    "    alert_cycles = motor_data[motor_data['risk_level'] > 0]\n",
    "    \n",
    "    if len(alert_cycles) > 0:\n",
    "        first_alert = alert_cycles.iloc[0]\n",
    "        alert_history.append({\n",
    "            'Moteur': motor,\n",
    "            'Cycle Alerte': int(first_alert['cycle']),\n",
    "            'RUL Alerte': int(first_alert['RUL']),\n",
    "            'Type': 'Attention âš ï¸' if first_alert['risk_level'] == 1 else 'Critique ğŸ”´'\n",
    "        })\n",
    "\n",
    "if alert_history:\n",
    "    alert_df = pd.DataFrame(alert_history)\n",
    "    print(alert_df.to_string(index=False))\n",
    "else:\n",
    "    print(\"Aucune alerte dÃ©tectÃ©e dans les 15 premiers moteurs\")\n",
    "\n",
    "print(\"\\nâœ… Onglet 4 complÃ©tÃ©\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e9b966",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nğŸ“Š ONGLET 3 : PRÃ‰DICTION & MAINTENANCE\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# PrÃ©dictions RUL pour moteurs sÃ©lectionnÃ©s\n",
    "selected_motors = [1, 10, 20, 50]\n",
    "\n",
    "print(f\"\\nğŸ¯ PrÃ©dictions RUL pour moteurs: {selected_motors}\")\n",
    "\n",
    "fig_pred = make_subplots(\n",
    "    rows=2, cols=2,\n",
    "    subplot_titles=[f'Moteur {m}' for m in selected_motors],\n",
    "    vertical_spacing=0.15,\n",
    "    horizontal_spacing=0.12\n",
    ")\n",
    "\n",
    "for idx, motor in enumerate(selected_motors):\n",
    "    row = (idx // 2) + 1\n",
    "    col = (idx % 2) + 1\n",
    "    \n",
    "    motor_train = train_features[train_features['unit'] == motor].sort_values('cycle')\n",
    "    \n",
    "    if len(motor_train) > 0:\n",
    "        # RUL RÃ©el\n",
    "        fig_pred.add_trace(\n",
    "            go.Scatter(\n",
    "                x=motor_train['cycle'],\n",
    "                y=motor_train['RUL'],\n",
    "                name=f'RÃ©el (M{motor})',\n",
    "                line=dict(color='royalblue', width=2),\n",
    "                mode='lines'\n",
    "            ),\n",
    "            row=row, col=col\n",
    "        )\n",
    "        \n",
    "        # RUL PrÃ©dit\n",
    "        fig_pred.add_trace(\n",
    "            go.Scatter(\n",
    "                x=motor_train['cycle'],\n",
    "                y=motor_train['RUL_predicted'],\n",
    "                name=f'PrÃ©dit (M{motor})',\n",
    "                line=dict(color='red', width=2, dash='dash'),\n",
    "                mode='lines'\n",
    "            ),\n",
    "            row=row, col=col\n",
    "        )\n",
    "        \n",
    "        # Seuils\n",
    "        fig_pred.add_hline(y=CRITICAL_THRESHOLD, line_dash='dash', line_color='red', row=row, col=col)\n",
    "        fig_pred.add_hline(y=WARNING_THRESHOLD, line_dash='dash', line_color='orange', row=row, col=col)\n",
    "\n",
    "fig_pred.update_xaxes(title_text='Cycle', row=1, col=1)\n",
    "fig_pred.update_yaxes(title_text='RUL (cycles)', row=1, col=1)\n",
    "\n",
    "fig_pred.update_layout(\n",
    "    height=700,\n",
    "    title_text='PrÃ©dictions RUL - Trajectoires de DÃ©gradation',\n",
    "    showlegend=True,\n",
    "    template='plotly_white',\n",
    "    hovermode='x unified'\n",
    ")\n",
    "\n",
    "fig_pred.show()\n",
    "\n",
    "# Timeline de maintenance\n",
    "print(\"\\nğŸ“… Timeline de Maintenance RecommandÃ©e (Top 10):\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "maintenance_timeline = []\n",
    "for motor in sorted(train_features['unit'].unique()):\n",
    "    motor_test = test_features[test_features['unit'] == motor].sort_values('cycle')\n",
    "    if len(motor_test) > 0:\n",
    "        final_cycle = motor_test.iloc[-1]['cycle']\n",
    "        predicted_rul = motor_test.iloc[-1]['RUL_predicted']\n",
    "        predicted_failure = final_cycle + predicted_rul\n",
    "        \n",
    "        maintenance_timeline.append({\n",
    "            'Moteur': motor,\n",
    "            'Cycle Actuel': int(final_cycle),\n",
    "            'RUL PrÃ©dit': int(predicted_rul),\n",
    "            'Panne EstimÃ©e': int(predicted_failure),\n",
    "            'Urgence': ['Normal', 'Attention', 'Critique'][int(test_features[test_features['unit'] == motor].iloc[-1]['risk_level'])]\n",
    "        })\n",
    "\n",
    "maint_df = pd.DataFrame(maintenance_timeline).sort_values('RUL PrÃ©dit')\n",
    "\n",
    "# Afficher top 10\n",
    "print(maint_df.head(10).to_string(index=False))\n",
    "\n",
    "# Visualisation Plotly\n",
    "fig_maint = px.bar(\n",
    "    maint_df.head(10),\n",
    "    x='Moteur',\n",
    "    y='RUL PrÃ©dit',\n",
    "    color='Urgence',\n",
    "    color_discrete_map={'Normal': '#2ecc71', 'Attention': '#f39c12', 'Critique': '#e74c3c'},\n",
    "    title='Top 10 Moteurs - PrÃ©diction du Cycle de Maintenance',\n",
    "    labels={'Moteur': 'Moteur', 'RUL PrÃ©dit': 'RUL PrÃ©dit (cycles)'},\n",
    "    height=500\n",
    ")\n",
    "\n",
    "fig_maint.update_layout(template='plotly_white')\n",
    "fig_maint.show()\n",
    "\n",
    "print(\"\\nâœ… Onglet 3 complÃ©tÃ©\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4a055f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nğŸ“Š ONGLET 2 : ANALYSE DE FLOTTE - CLUSTERING\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# Visualisation interactive des clusters\n",
    "cluster_analysis = []\n",
    "for motor in sorted(train_features['unit'].unique()):\n",
    "    motor_data = train_features[train_features['unit'] == motor]\n",
    "    cluster_analysis.append({\n",
    "        'motor': motor,\n",
    "        'cluster': motor_cluster_map[motor],\n",
    "        'avg_sensor2': motor_data['sensor2'].mean(),\n",
    "        'avg_sensor7': motor_data['sensor7'].mean(),\n",
    "        'rul_mean': motor_data['RUL'].mean(),\n",
    "        'cycles': motor_data['cycle'].max()\n",
    "    })\n",
    "\n",
    "cluster_df_motors = pd.DataFrame(cluster_analysis)\n",
    "\n",
    "fig_cluster = px.scatter(\n",
    "    cluster_df_motors,\n",
    "    x='avg_sensor2',\n",
    "    y='avg_sensor7',\n",
    "    color='cluster',\n",
    "    size='cycles',\n",
    "    hover_data=['motor', 'rul_mean'],\n",
    "    title='Analyse de Flotte - Clusters de Moteurs (Sensor2 vs Sensor7)',\n",
    "    labels={'avg_sensor2': 'Sensor 2 (Moyen)', 'avg_sensor7': 'Sensor 7 (Moyen)', 'cluster': 'Cluster'},\n",
    "    color_discrete_sequence=['#FF6B6B', '#4ECDC4', '#45B7D1'],\n",
    "    height=600\n",
    ")\n",
    "\n",
    "fig_cluster.update_traces(marker=dict(opacity=0.7))\n",
    "fig_cluster.update_layout(template='plotly_white', hovermode='closest')\n",
    "fig_cluster.show()\n",
    "\n",
    "# CaractÃ©ristiques par cluster\n",
    "print(\"\\nğŸ“‹ Profils des Clusters:\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "for c in range(optimal_k):\n",
    "    cluster_motors = cluster_df_motors[cluster_df_motors['cluster'] == c]['motor'].values\n",
    "    cluster_subset = train_features[train_features['unit'].isin(cluster_motors)]\n",
    "    \n",
    "    print(f\"\\nCluster {c}:\")\n",
    "    print(f\"   Moteurs: {', '.join(map(str, cluster_motors[:5]))}{'...' if len(cluster_motors) > 5 else ''}\")\n",
    "    print(f\"   Nombre total: {len(cluster_motors)}\")\n",
    "    print(f\"   RUL moyen: {cluster_subset['RUL'].mean():.1f} cycles\")\n",
    "    print(f\"   Sensor2 moyen: {cluster_subset['sensor2'].mean():.4f}\")\n",
    "    print(f\"   Sensor7 moyen: {cluster_subset['sensor7'].mean():.4f}\")\n",
    "\n",
    "print(\"\\nâœ… Onglet 2 complÃ©tÃ©\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e123142b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"Ã‰TAPE 8 : CONSTRUCTION DU DASHBOARD INTERACTIF\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\nğŸ“Š ONGLET 1 : VUE D'ENSEMBLE EXECUTIVE\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# Calcul des KPIs\n",
    "total_engines = train_features['unit'].nunique()\n",
    "engines_critical = (train_features['risk_level'] == 2).nunique()\n",
    "engines_warning = (train_features['risk_level'] == 1).nunique()\n",
    "avg_rul = train_features['RUL'].mean()\n",
    "\n",
    "print(f\"   KPIs CalculÃ©s:\")\n",
    "print(f\"     â€¢ Total moteurs: {total_engines}\")\n",
    "print(f\"     â€¢ Moteurs critiques: {engines_critical}\")\n",
    "print(f\"     â€¢ Moteurs attention: {engines_warning}\")\n",
    "print(f\"     â€¢ RUL moyen: {avg_rul:.0f} cycles\")\n",
    "\n",
    "# Cartes KPI avec Plotly\n",
    "fig_kpi = make_subplots(\n",
    "    rows=1, cols=3,\n",
    "    specs=[[{'type':'indicator'}, {'type':'indicator'}, {'type':'indicator'}]]\n",
    ")\n",
    "\n",
    "fig_kpi.add_trace(\n",
    "    go.Indicator(\n",
    "        mode='number',\n",
    "        value=total_engines,\n",
    "        title='Moteurs Total',\n",
    "        domain={'x': [0, 1], 'y': [0, 1]}\n",
    "    ),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "fig_kpi.add_trace(\n",
    "    go.Indicator(\n",
    "        mode='number',\n",
    "        value=engines_critical + engines_warning,\n",
    "        title='Moteurs Ã  Risque',\n",
    "        number={'valueformat': 'd'},\n",
    "        domain={'x': [0, 1], 'y': [0, 1]}\n",
    "    ),\n",
    "    row=1, col=2\n",
    ")\n",
    "\n",
    "fig_kpi.add_trace(\n",
    "    go.Indicator(\n",
    "        mode='number',\n",
    "        value=round(avg_rul),\n",
    "        title='RUL Moyen (cycles)',\n",
    "        number={'valueformat': 'd'},\n",
    "        domain={'x': [0, 1], 'y': [0, 1]}\n",
    "    ),\n",
    "    row=1, col=3\n",
    ")\n",
    "\n",
    "fig_kpi.update_layout(\n",
    "    height=300,\n",
    "    showlegend=False,\n",
    "    title_text='ğŸ’¡ KPIs ClÃ©s - Vue ExÃ©cutive',\n",
    "    template='plotly_white'\n",
    ")\n",
    "\n",
    "fig_kpi.show()\n",
    "\n",
    "# Graphique d'Ã©volution des risques par moteur\n",
    "print(\"\\nğŸ“ˆ Graphique: RUL Final par Moteur\")\n",
    "\n",
    "risk_evolution = []\n",
    "for motor in sorted(train_features['unit'].unique()):\n",
    "    motor_data = train_features[train_features['unit'] == motor].sort_values('cycle')\n",
    "    final_risk = motor_data.iloc[-1]['risk_level']\n",
    "    risk_evolution.append({\n",
    "        'motor': motor,\n",
    "        'final_risk': final_risk,\n",
    "        'rul_final': motor_data.iloc[-1]['RUL']\n",
    "    })\n",
    "\n",
    "risk_df = pd.DataFrame(risk_evolution)\n",
    "\n",
    "fig_risk = px.scatter(\n",
    "    risk_df,\n",
    "    x='motor',\n",
    "    y='rul_final',\n",
    "    color='final_risk',\n",
    "    color_discrete_map={0: '#2ecc71', 1: '#f39c12', 2: '#e74c3c'},\n",
    "    title='RUL Final par Moteur - Codes Couleur par Niveau de Risque',\n",
    "    labels={'motor': 'Moteur', 'rul_final': 'RUL Final (cycles)', 'final_risk': 'Risque'},\n",
    "    height=500\n",
    ")\n",
    "\n",
    "# Ajouter des lignes de seuil\n",
    "fig_risk.add_hline(y=CRITICAL_THRESHOLD, line_dash='dash', line_color='red', \n",
    "                   annotation_text='Seuil Critique', annotation_position='right')\n",
    "fig_risk.add_hline(y=WARNING_THRESHOLD, line_dash='dash', line_color='orange',\n",
    "                   annotation_text='Seuil Attention', annotation_position='right')\n",
    "\n",
    "fig_risk.update_layout(template='plotly_white', hovermode='closest')\n",
    "fig_risk.show()\n",
    "\n",
    "print(\"âœ… Onglet 1 complÃ©tÃ©\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d38ec61c",
   "metadata": {},
   "source": [
    "## 8ï¸âƒ£ DASHBOARD INTERACTIF - VISUALISATIONS PLOTLY\n",
    "\n",
    "### 4 Onglets ThÃ©matiques\n",
    "1. **Vue d'Ensemble** : KPIs et indicateurs clÃ©s\n",
    "2. **Analyse de Flotte** : Clusters et segments\n",
    "3. **PrÃ©diction & Maintenance** : RUL et timeline\n",
    "4. **Monitoring** : Heatmaps et anomalies\n",
    "\n",
    "Chaque onglet combine donnÃ©es opÃ©rationnelles et visuels interactifs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9332ef7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PrÃ©dictions d'alerte et visualisation\n",
    "X_test_class = test_features[feature_cols].values\n",
    "X_test_class_scaled = scaler_model.transform(X_test_class)\n",
    "risk_predictions = best_classifier.predict(X_test_class_scaled)\n",
    "risk_probabilities = best_classifier.predict_proba(X_test_class_scaled)\n",
    "\n",
    "test_features['risk_predicted'] = risk_predictions\n",
    "test_features['risk_probability_critical'] = risk_probabilities[:, 2] if risk_probabilities.shape[1] > 2 else 0\n",
    "\n",
    "train_features['risk_predicted'] = best_classifier.predict(scaler_model.transform(X_train_class))\n",
    "\n",
    "# Matrice de confusion sur donnÃ©es de validation\n",
    "y_pred_val_class = best_classifier.predict(X_val_class)\n",
    "cm = confusion_matrix(y_val_class, y_pred_val_class)\n",
    "\n",
    "# Visualisation avec Plotly\n",
    "print(\"\\nğŸ“Š Visualisation de la Matrice de Confusion...\")\n",
    "\n",
    "# CrÃ©er la heatmap\n",
    "cm_labels = ['Normal', 'Attention', 'Critique']\n",
    "fig_cm = go.Figure(data=go.Heatmap(\n",
    "    z=cm,\n",
    "    x=cm_labels,\n",
    "    y=cm_labels,\n",
    "    colorscale='Blues',\n",
    "    text=cm,\n",
    "    texttemplate='%{text}',\n",
    "    textfont={\"size\": 12},\n",
    "    colorbar=dict(title='Nombre')\n",
    "))\n",
    "\n",
    "fig_cm.update_layout(\n",
    "    title='Matrice de Confusion - SystÃ¨me d\\'Alerte',\n",
    "    xaxis_title='PrÃ©diction',\n",
    "    yaxis_title='RÃ©alitÃ©',\n",
    "    height=500,\n",
    "    width=600,\n",
    "    template='plotly_white'\n",
    ")\n",
    "\n",
    "fig_cm.show()\n",
    "\n",
    "# Distribution des prÃ©dictions d'alerte\n",
    "print(\"\\nğŸ“Š Distribution des Alertes PrÃ©dites...\")\n",
    "\n",
    "alert_counts = pd.Series(risk_predictions).value_counts().sort_index()\n",
    "alert_labels = ['Normal', 'Attention', 'Critique'][:len(alert_counts)]\n",
    "alert_colors = ['#2ecc71', '#f39c12', '#e74c3c']\n",
    "\n",
    "fig_alert_dist = go.Figure(data=[\n",
    "    go.Bar(\n",
    "        x=alert_labels,\n",
    "        y=alert_counts.values,\n",
    "        marker_color=alert_colors[:len(alert_counts)],\n",
    "        text=alert_counts.values,\n",
    "        textposition='outside'\n",
    "    )\n",
    "])\n",
    "\n",
    "fig_alert_dist.update_layout(\n",
    "    title='Distribution des PrÃ©dictions d\\'Alerte (DonnÃ©es Test)',\n",
    "    xaxis_title='Niveau de Risque',\n",
    "    yaxis_title='Nombre d\\'Enregistrements',\n",
    "    template='plotly_white',\n",
    "    height=450\n",
    ")\n",
    "\n",
    "fig_alert_dist.show()\n",
    "\n",
    "print(\"âœ… SystÃ¨me d'alerte mis en place\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789b83d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"Ã‰TAPE 7 : CLASSIFICATION - SYSTÃˆME D'ALERTE DE MAINTENANCE\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "# DÃ©finir les seuils de risque\n",
    "CRITICAL_THRESHOLD = 30  # RUL < 30 = critique\n",
    "WARNING_THRESHOLD = 50   # RUL < 50 = attention\n",
    "\n",
    "# CrÃ©er les labels de classe\n",
    "def classify_rul(rul):\n",
    "    \"\"\"Classifie le RUL en 3 catÃ©gories de risque\"\"\"\n",
    "    if rul < CRITICAL_THRESHOLD:\n",
    "        return 2  # Critique ğŸ”´\n",
    "    elif rul < WARNING_THRESHOLD:\n",
    "        return 1  # Attention ğŸŸ¡\n",
    "    else:\n",
    "        return 0  # Normal ğŸŸ¢\n",
    "\n",
    "train_features['risk_level'] = train_features['RUL'].apply(classify_rul)\n",
    "test_features['risk_level'] = test_features['RUL'].apply(classify_rul)\n",
    "\n",
    "print(f\"\\nâš ï¸ Seuils de Classification:\")\n",
    "print(f\"   ğŸŸ¢ Normal:     RUL â‰¥ {WARNING_THRESHOLD} cycles\")\n",
    "print(f\"   ğŸŸ¡ Attention:  {CRITICAL_THRESHOLD} â‰¤ RUL < {WARNING_THRESHOLD} cycles\")\n",
    "print(f\"   ğŸ”´ Critique:   RUL < {CRITICAL_THRESHOLD} cycles\")\n",
    "\n",
    "# Distribution des classes\n",
    "print(f\"\\nğŸ“Š Distribution des Classes (donnÃ©es d'entraÃ®nement):\")\n",
    "class_labels = {0: 'Normal', 1: 'Attention', 2: 'Critique'}\n",
    "for level in [0, 1, 2]:\n",
    "    count = (train_features['risk_level'] == level).sum()\n",
    "    pct = 100 * count / len(train_features)\n",
    "    print(f\"   {class_labels[level]:10s}: {count:5d} ({pct:5.1f}%)\")\n",
    "\n",
    "# PrÃ©parer les donnÃ©es de classification\n",
    "X_train_class = train_features[feature_cols].values\n",
    "y_train_class = train_features['risk_level'].values\n",
    "\n",
    "X_tr_class, X_val_class, y_tr_class, y_val_class = train_test_split(\n",
    "    scaler_model.transform(X_train_class), y_train_class, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# EntraÃ®ner les classifieurs\n",
    "classifiers = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000, random_state=42),\n",
    "    'SVM': SVC(kernel='rbf', probability=True, random_state=42),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
    "}\n",
    "\n",
    "class_results = {}\n",
    "print(f\"\\nğŸ¤– EntraÃ®nement des Classifieurs:\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "for name, clf in classifiers.items():\n",
    "    clf.fit(X_tr_class, y_tr_class)\n",
    "    y_pred_val_class = clf.predict(X_val_class)\n",
    "    \n",
    "    accuracy = accuracy_score(y_val_class, y_pred_val_class)\n",
    "    precision = precision_score(y_val_class, y_pred_val_class, average='weighted', zero_division=0)\n",
    "    recall = recall_score(y_val_class, y_pred_val_class, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(y_val_class, y_pred_val_class, average='weighted', zero_division=0)\n",
    "    \n",
    "    class_results[name] = {\n",
    "        'model': clf,\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1\n",
    "    }\n",
    "    \n",
    "    print(f\"\\n{name:20s}\")\n",
    "    print(f\"   Accuracy:  {accuracy:.4f} (proportion correctes)\")\n",
    "    print(f\"   Precision: {precision:.4f} (faux positifs minimisÃ©s)\")\n",
    "    print(f\"   Recall:    {recall:.4f} (cas positifs trouvÃ©s)\")\n",
    "    print(f\"   F1-Score:  {f1:.4f} (harmonie precision-recall)\")\n",
    "\n",
    "# SÃ©lectionner le meilleur classifieur\n",
    "best_classifier_name = max(class_results, key=lambda x: class_results[x]['f1'])\n",
    "best_classifier = class_results[best_classifier_name]['model']\n",
    "\n",
    "print(f\"\\nâœ… Meilleur classifieur: {best_classifier_name} (F1 = {class_results[best_classifier_name]['f1']:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06169e9d",
   "metadata": {},
   "source": [
    "## 7ï¸âƒ£ CLASSIFICATION - SYSTÃˆME D'ALERTE INTELLIGENT\n",
    "\n",
    "### Seuils de Risque\n",
    "- ğŸŸ¢ **Normal** : RUL â‰¥ 50 cycles\n",
    "- ğŸŸ¡ **Attention** : 30 â‰¤ RUL < 50 cycles\n",
    "- ğŸ”´ **Critique** : RUL < 30 cycles\n",
    "\n",
    "### ModÃ¨les ComparÃ©s\n",
    "- Logistic Regression (rapide, interprÃ©table)\n",
    "- SVM (robuste, non-linÃ©aire)\n",
    "- Gradient Boosting (gÃ©nÃ©ralement meilleur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc6c9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation des performances avec Plotly\n",
    "print(\"\\nğŸ“Š Comparaison des modÃ¨les...\")\n",
    "\n",
    "fig_models = make_subplots(\n",
    "    rows=1, cols=3,\n",
    "    subplot_titles=('MAE (plus bas = meilleur)', 'RMSE (plus bas = meilleur)', 'RÂ² (plus haut = meilleur)'),\n",
    "    specs=[[{'type':'bar'}, {'type':'bar'}, {'type':'bar'}]]\n",
    ")\n",
    "\n",
    "model_names = list(results.keys())\n",
    "maes = [results[m]['mae'] for m in model_names]\n",
    "rmses = [results[m]['rmse'] for m in model_names]\n",
    "r2s = [results[m]['r2'] for m in model_names]\n",
    "\n",
    "colors = ['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4']\n",
    "\n",
    "fig_models.add_trace(\n",
    "    go.Bar(x=model_names, y=maes, marker_color=colors[0], name='MAE'),\n",
    "    row=1, col=1\n",
    ")\n",
    "fig_models.add_trace(\n",
    "    go.Bar(x=model_names, y=rmses, marker_color=colors[1], name='RMSE'),\n",
    "    row=1, col=2\n",
    ")\n",
    "fig_models.add_trace(\n",
    "    go.Bar(x=model_names, y=r2s, marker_color=colors[2], name='RÂ²'),\n",
    "    row=1, col=3\n",
    ")\n",
    "\n",
    "fig_models.update_xaxes(tickangle=45, row=1, col=1)\n",
    "fig_models.update_xaxes(tickangle=45, row=1, col=2)\n",
    "fig_models.update_xaxes(tickangle=45, row=1, col=3)\n",
    "\n",
    "fig_models.update_layout(\n",
    "    height=450,\n",
    "    title_text=\"Comparaison des ModÃ¨les de RÃ©gression\",\n",
    "    showlegend=False,\n",
    "    template='plotly_white'\n",
    ")\n",
    "\n",
    "fig_models.show()\n",
    "\n",
    "print(\"âœ… ModÃ¨les comparÃ©s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b1dfdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"Ã‰TAPE 6 : MODÃ‰LISATION - PRÃ‰DICTION DU RUL\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# PrÃ©parer les features pour la modÃ©lisation\n",
    "feature_cols = sensor_cols + [col for col in train_features.columns if '_ma' in col or '_std' in col or '_delta' in col]\n",
    "feature_cols = [col for col in feature_cols if col in train_features.columns]\n",
    "\n",
    "X_train = train_features[feature_cols].values\n",
    "y_train = train_features['RUL'].values\n",
    "\n",
    "# Normaliser les features\n",
    "scaler_model = StandardScaler()\n",
    "X_train_scaled = scaler_model.fit_transform(X_train)\n",
    "\n",
    "# Diviser en train/validation\n",
    "X_tr, X_val, y_tr, y_val = train_test_split(X_train_scaled, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"\\nğŸ“Š Configuration de l'expÃ©rience:\")\n",
    "print(f\"   Features: {len(feature_cols)}\")\n",
    "print(f\"   EntraÃ®nement: {X_tr.shape[0]} enregistrements\")\n",
    "print(f\"   Validation: {X_val.shape[0]} enregistrements\")\n",
    "\n",
    "# EntraÃ®ner plusieurs modÃ¨les\n",
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Random Forest': RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1),\n",
    "    'Gradient Boosting': GradientBoostingRegressor(n_estimators=100, random_state=42),\n",
    "    'Neural Network': MLPRegressor(hidden_layer_sizes=(100, 50), max_iter=500, random_state=42)\n",
    "}\n",
    "\n",
    "results = {}\n",
    "print(f\"\\nğŸ¤– EntraÃ®nement des modÃ¨les:\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "for name, model in models.items():\n",
    "    # EntraÃ®ner\n",
    "    model.fit(X_tr, y_tr)\n",
    "    \n",
    "    # PrÃ©dire\n",
    "    y_pred_val = model.predict(X_val)\n",
    "    \n",
    "    # Ã‰valuer\n",
    "    mae = mean_absolute_error(y_val, y_pred_val)\n",
    "    rmse = np.sqrt(mean_squared_error(y_val, y_pred_val))\n",
    "    r2 = r2_score(y_val, y_pred_val)\n",
    "    \n",
    "    results[name] = {\n",
    "        'model': model,\n",
    "        'mae': mae,\n",
    "        'rmse': rmse,\n",
    "        'r2': r2\n",
    "    }\n",
    "    \n",
    "    print(f\"\\n{name:20s}\")\n",
    "    print(f\"   MAE  (Mean Absolute Error): {mae:7.2f} cycles\")\n",
    "    print(f\"   RMSE (Root Mean Squared):  {rmse:7.2f} cycles\")\n",
    "    print(f\"   RÂ²   (Variance expliquÃ©e):  {r2:7.4f}\")\n",
    "\n",
    "# SÃ©lectionner le meilleur modÃ¨le\n",
    "best_model_name = max(results, key=lambda x: results[x]['r2'])\n",
    "best_model = results[best_model_name]['model']\n",
    "\n",
    "print(f\"\\nâœ… Meilleur modÃ¨le: {best_model_name} (RÂ² = {results[best_model_name]['r2']:.4f})\")\n",
    "\n",
    "# PrÃ©dictions finales sur donnÃ©es de test\n",
    "X_test = test_features[feature_cols].values\n",
    "X_test_scaled = scaler_model.transform(X_test)\n",
    "y_pred_test = best_model.predict(X_test_scaled)\n",
    "\n",
    "test_features['RUL_predicted'] = y_pred_test\n",
    "y_pred_train = best_model.predict(X_train_scaled)\n",
    "train_features['RUL_predicted'] = y_pred_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa8971b",
   "metadata": {},
   "source": [
    "## 6ï¸âƒ£ MODÃ‰LISATION - PRÃ‰DICTION DU RUL\n",
    "\n",
    "### Approche Multi-ModÃ¨les\n",
    "Comparer 4 architectures diffÃ©rentes pour trouver le meilleur prÃ©dicteur du RUL :\n",
    "- **Linear Regression** : baseline simple et interprÃ©table\n",
    "- **Random Forest** : robuste aux non-linÃ©aritÃ©s\n",
    "- **Gradient Boosting** : amÃ©lioration itÃ©rative, gÃ©nÃ©ralement meilleur\n",
    "- **Neural Network** : capture les patterns complexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f88bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation des clusters en 2D avec PCA et Plotly\n",
    "print(\"\\nğŸ“ Visualisation des clusters...\")\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "motor_profiles_pca = pca.fit_transform(motor_profiles_scaled)\n",
    "\n",
    "# DataFrame pour Plotly\n",
    "cluster_viz_df = pd.DataFrame({\n",
    "    'PC1': motor_profiles_pca[:, 0],\n",
    "    'PC2': motor_profiles_pca[:, 1],\n",
    "    'Cluster': clusters,\n",
    "    'Moteur': motor_ids\n",
    "})\n",
    "\n",
    "fig_clusters = px.scatter(\n",
    "    cluster_viz_df,\n",
    "    x='PC1',\n",
    "    y='PC2',\n",
    "    color='Cluster',\n",
    "    text='Moteur',\n",
    "    size_max=15,\n",
    "    title='Segmentation des Moteurs - Analyse en Composantes Principales',\n",
    "    labels={'Cluster': 'Cluster de Moteurs'},\n",
    "    color_discrete_sequence=['#FF6B6B', '#4ECDC4', '#45B7D1'],\n",
    "    height=600\n",
    ")\n",
    "\n",
    "fig_clusters.update_traces(textposition='top center', marker=dict(size=10, opacity=0.7))\n",
    "fig_clusters.update_xaxes(title_text=f'PC1 ({pca.explained_variance_ratio_[0]:.1%} variance)')\n",
    "fig_clusters.update_yaxes(title_text=f'PC2 ({pca.explained_variance_ratio_[1]:.1%} variance)')\n",
    "fig_clusters.update_layout(template='plotly_white', hovermode='closest')\n",
    "fig_clusters.show()\n",
    "\n",
    "# Analyse des caractÃ©ristiques par cluster\n",
    "print(\"\\nğŸ” Analyse des Clusters:\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "cluster_summary = []\n",
    "for c in range(optimal_k):\n",
    "    cluster_motors = [motor_ids[i] for i in range(len(motor_ids)) if clusters[i] == c]\n",
    "    cluster_data = train_features[train_features['unit'].isin(cluster_motors)]\n",
    "    \n",
    "    avg_rul = cluster_data['RUL'].mean()\n",
    "    num_motors = len(cluster_motors)\n",
    "    avg_cycles = cluster_data.groupby('unit')['cycle'].max().mean()\n",
    "    \n",
    "    cluster_summary.append({\n",
    "        'Cluster': c,\n",
    "        'Moteurs': num_motors,\n",
    "        'RUL Moyen': round(avg_rul, 1),\n",
    "        'Cycles Moyen': round(avg_cycles, 0)\n",
    "    })\n",
    "    \n",
    "    print(f\"Cluster {c}:\")\n",
    "    print(f\"   â€¢ Nombre de moteurs: {num_motors}\")\n",
    "    print(f\"   â€¢ RUL moyen: {avg_rul:.1f} cycles\")\n",
    "    print(f\"   â€¢ Cycles avant panne: {avg_cycles:.0f}\")\n",
    "\n",
    "# Tableau rÃ©capitulatif\n",
    "cluster_df = pd.DataFrame(cluster_summary)\n",
    "print(\"\\n\" + cluster_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e02d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"Ã‰TAPE 5 : CLUSTERING - SEGMENTATION DES PROFILS DE DÃ‰GRADATION\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import silhouette_score, davies_bouldin_score\n",
    "\n",
    "# AgrÃ©gation par moteur - crÃ©er un profil moyen par moteur\n",
    "print(\"\\nğŸ”§ CrÃ©ation des profils moteurs (agrÃ©gation)...\")\n",
    "\n",
    "motor_profiles = []\n",
    "motor_ids = []\n",
    "\n",
    "for motor in sorted(train_features['unit'].unique()):\n",
    "    motor_data = train_features[train_features['unit'] == motor]\n",
    "    profile = motor_data[sensor_cols].mean().values\n",
    "    rul_mean = motor_data['RUL'].mean()\n",
    "    motor_profiles.append(np.concatenate([profile, [rul_mean]]))\n",
    "    motor_ids.append(motor)\n",
    "\n",
    "motor_profiles = np.array(motor_profiles)\n",
    "print(f\"âœ“ {len(motor_ids)} profils moteurs crÃ©Ã©s\")\n",
    "\n",
    "# Normalisation pour le clustering\n",
    "scaler_cluster = StandardScaler()\n",
    "motor_profiles_scaled = scaler_cluster.fit_transform(motor_profiles)\n",
    "\n",
    "# DÃ©terminer le nombre optimal de clusters\n",
    "print(\"\\nğŸ“Š DÃ©termination du nombre optimal de clusters (k)...\")\n",
    "\n",
    "inertias = []\n",
    "silhouette_scores = []\n",
    "K_range = range(2, 8)\n",
    "\n",
    "for k in K_range:\n",
    "    kmeans_temp = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    kmeans_temp.fit(motor_profiles_scaled)\n",
    "    inertias.append(kmeans_temp.inertia_)\n",
    "    silhouette_scores.append(silhouette_score(motor_profiles_scaled, kmeans_temp.labels_))\n",
    "\n",
    "# Visualisation interactive de l'elbow method\n",
    "fig_elbow = make_subplots(\n",
    "    rows=1, cols=2,\n",
    "    subplot_titles=('Elbow Method', 'Silhouette Score'),\n",
    "    specs=[[{'secondary_y': False}, {'secondary_y': False}]]\n",
    ")\n",
    "\n",
    "fig_elbow.add_trace(\n",
    "    go.Scatter(x=list(K_range), y=inertias, mode='lines+markers', name='Inertie',\n",
    "               line=dict(color='royalblue', width=3), marker=dict(size=8)),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "fig_elbow.add_trace(\n",
    "    go.Scatter(x=list(K_range), y=silhouette_scores, mode='lines+markers', name='Silhouette',\n",
    "               line=dict(color='green', width=3), marker=dict(size=8)),\n",
    "    row=1, col=2\n",
    ")\n",
    "\n",
    "fig_elbow.update_xaxes(title_text=\"Nombre de Clusters (k)\", row=1, col=1)\n",
    "fig_elbow.update_yaxes(title_text=\"Inertie\", row=1, col=1)\n",
    "fig_elbow.update_xaxes(title_text=\"Nombre de Clusters (k)\", row=1, col=2)\n",
    "fig_elbow.update_yaxes(title_text=\"Silhouette Score\", row=1, col=2)\n",
    "fig_elbow.update_layout(height=400, template='plotly_white', showlegend=True)\n",
    "fig_elbow.show()\n",
    "\n",
    "# SÃ©lectionner k=3 pour une segmentation claire\n",
    "optimal_k = 3\n",
    "print(f\"âœ“ Nombre optimal de clusters: {optimal_k}\")\n",
    "\n",
    "kmeans = KMeans(n_clusters=optimal_k, random_state=42, n_init=10)\n",
    "clusters = kmeans.fit_predict(motor_profiles_scaled)\n",
    "\n",
    "# Calculer les mÃ©triques de qualitÃ©\n",
    "silhouette_avg = silhouette_score(motor_profiles_scaled, clusters)\n",
    "davies_bouldin = davies_bouldin_score(motor_profiles_scaled, clusters)\n",
    "\n",
    "print(f\"\\nğŸ“ˆ MÃ©triques de clustering:\")\n",
    "print(f\"   Silhouette Score: {silhouette_avg:.4f} (meilleur âˆˆ [-1, 1], optimum = 1)\")\n",
    "print(f\"   Davies-Bouldin Index: {davies_bouldin:.4f} (plus bas = meilleur, optimum = 0)\")\n",
    "\n",
    "# Ajouter les clusters aux donnÃ©es\n",
    "motor_cluster_map = {motor_ids[i]: clusters[i] for i in range(len(motor_ids))}\n",
    "train_features['cluster'] = train_features['unit'].map(motor_cluster_map)\n",
    "test_features['cluster'] = test_features['unit'].map(motor_cluster_map)\n",
    "\n",
    "print(f\"âœ… Clustering complÃ©tÃ©\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef16e58",
   "metadata": {},
   "source": [
    "## 5ï¸âƒ£ CLUSTERING - SEGMENTATION DES PROFILS\n",
    "\n",
    "### StratÃ©gie\n",
    "1. **AgrÃ©gation** : CrÃ©er un profil moyen par moteur\n",
    "2. **DÃ©terminer k** : Elbow method + Silhouette score\n",
    "3. **K-Means** : Segmenter les moteurs en groupes similaires\n",
    "4. **InterprÃ©tation** : Analyser les caractÃ©ristiques de chaque cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf6435f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DÃ©tection d'anomalies avec Isolation Forest\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "print(\"\\nğŸš¨ DÃ©tection d'Anomalies\")\n",
    "\n",
    "iso_forest = IsolationForest(contamination=0.05, random_state=42)\n",
    "anomalies = iso_forest.fit_predict(train_features[sensor_cols])\n",
    "train_features['anomaly'] = anomalies\n",
    "\n",
    "anomaly_count = (anomalies == -1).sum()\n",
    "print(f\"   Anomalies dÃ©tectÃ©es: {anomaly_count} sur {len(anomalies)} enregistrements ({100*anomaly_count/len(anomalies):.2f}%)\")\n",
    "\n",
    "# Visualisation des anomalies avec Plotly\n",
    "print(\"\\nğŸ“ Graphique 3 : DÃ©tection d'Anomalies Interactif\")\n",
    "\n",
    "# PrÃ©parer donnÃ©es pour Plotly\n",
    "anomaly_viz_data = []\n",
    "for motor in [1, 5, 10, 20]:\n",
    "    motor_data = train_features[train_features['unit'] == motor].copy()\n",
    "    motor_data['motor'] = motor\n",
    "    anomaly_viz_data.append(motor_data)\n",
    "\n",
    "anomaly_df = pd.concat(anomaly_viz_data)\n",
    "anomaly_df['Statut'] = anomaly_df['anomaly'].map({1: 'Normal', -1: 'Anomalie'})\n",
    "\n",
    "fig_anomaly = px.scatter(\n",
    "    anomaly_df,\n",
    "    x='cycle',\n",
    "    y='sensor2',\n",
    "    color='Statut',\n",
    "    facet_col='motor',\n",
    "    facet_col_wrap=2,\n",
    "    title='DÃ©tection d\\'Anomalies par Moteur - Sensor2',\n",
    "    labels={'cycle': 'Cycle', 'sensor2': 'Sensor 2 (normalisÃ©)', 'motor': 'Moteur'},\n",
    "    color_discrete_map={'Normal': 'lightblue', 'Anomalie': 'red'},\n",
    "    height=600\n",
    ")\n",
    "\n",
    "fig_anomaly.update_traces(marker=dict(size=6))\n",
    "fig_anomaly.update_layout(hovermode='closest', template='plotly_white')\n",
    "fig_anomaly.show()\n",
    "\n",
    "print(\"âœ… Anomalies visualisÃ©es\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bda756d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"Ã‰TAPE 4 : ANALYSE EXPLORATOIRE AVANCÃ‰E - PROFILS DE DÃ‰GRADATION\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Visualisation 1: Profils de dÃ©gradation typiques pour plusieurs moteurs\n",
    "print(\"\\nğŸ“ˆ Graphique 1 : Trajectoires de dÃ©gradation (Matplotlib)\")\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 8))\n",
    "fig.suptitle('Profils de DÃ©gradation Typiques - Capteurs ClÃ©s', fontsize=14, fontweight='bold')\n",
    "\n",
    "moteurs_example = [1, 10, 25, 50]\n",
    "sensor_keys = ['sensor2', 'sensor3', 'sensor4', 'sensor7']\n",
    "\n",
    "for idx, ax in enumerate(axes.flat):\n",
    "    sensor = sensor_keys[idx]\n",
    "    for motor in moteurs_example:\n",
    "        motor_data = train_main_clean[train_main_clean['unit'] == motor]\n",
    "        ax.plot(motor_data['cycle'], motor_data[sensor], label=f'Moteur {motor}', alpha=0.7, linewidth=2)\n",
    "    \n",
    "    ax.set_xlabel('Cycle', fontsize=10)\n",
    "    ax.set_ylabel('Valeur Capteur (normalisÃ©e)', fontsize=10)\n",
    "    ax.set_title(f'{sensor.upper()}', fontsize=11, fontweight='bold')\n",
    "    ax.legend(fontsize=8, loc='best')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Visualisation 2: Distribution du RUL avec Plotly\n",
    "print(\"\\nğŸ“Š Graphique 2 : Distribution du RUL (Plotly Express)\")\n",
    "\n",
    "fig_rul_dist = px.histogram(\n",
    "    train_main_clean,\n",
    "    x='RUL',\n",
    "    nbins=30,\n",
    "    title='Distribution du RUL - Tous les Cycles',\n",
    "    labels={'RUL': 'RUL (cycles restants)', 'count': 'FrÃ©quence'},\n",
    "    color_discrete_sequence=['steelblue']\n",
    ")\n",
    "\n",
    "fig_rul_dist.update_traces(marker_edgecolor='white', marker_edgewidth=1)\n",
    "fig_rul_dist.update_layout(template='plotly_white', hovermode='x unified')\n",
    "fig_rul_dist.show()\n",
    "\n",
    "# Analyse de corrÃ©lation\n",
    "print(\"\\nğŸ”— Analyse de CorrÃ©lation\")\n",
    "sensor_cols = [col for col in train_features.columns if col.startswith('sensor') and '_' not in col]\n",
    "correlation_data = train_features[sensor_cols + ['RUL']].corr()\n",
    "\n",
    "print(f\"   Top 5 capteurs corrÃ©lÃ©s au RUL:\")\n",
    "rul_corr = correlation_data['RUL'].drop('RUL').abs().nlargest(5)\n",
    "for i, (sensor, corr) in enumerate(rul_corr.items(), 1):\n",
    "    print(f\"     {i}. {sensor:10s} â†’ r = {corr:+.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e28d0e1",
   "metadata": {},
   "source": [
    "## 4ï¸âƒ£ ANALYSE EXPLORATOIRE AVANCÃ‰E (EDA)\n",
    "\n",
    "### Visualisations ClÃ©s\n",
    "- Profils de dÃ©gradation typiques\n",
    "- Distribution du RUL\n",
    "- CorrÃ©lation capteurs-RUL\n",
    "- DÃ©tection d'anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34eb9a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"Ã‰TAPE 3 : FEATURE ENGINEERING - EXTRACTION DE SIGNAUX TEMPORELS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "def create_temporal_features(df, window_size=5):\n",
    "    \"\"\"\n",
    "    CrÃ©e des features temporelles pour chaque capteur et moteur.\n",
    "    \n",
    "    ParamÃ¨tres:\n",
    "    -----------\n",
    "    df : DataFrame\n",
    "        DonnÃ©es avec colonnes 'unit' et capteurs\n",
    "    window_size : int\n",
    "        Taille de la fenÃªtre glissante (par dÃ©faut 5 cycles)\n",
    "    \n",
    "    Retour:\n",
    "    -------\n",
    "    DataFrame enrichi avec features temporelles\n",
    "    \"\"\"\n",
    "    df_features = df.copy()\n",
    "    sensor_cols = [col for col in df.columns if col.startswith('sensor')]\n",
    "    \n",
    "    print(f\"\\n   CrÃ©ation de features sur fenÃªtre de {window_size} cycles...\")\n",
    "    \n",
    "    # Par moteur, crÃ©er les features\n",
    "    for unit in df['unit'].unique():\n",
    "        unit_mask = df_features['unit'] == unit\n",
    "        unit_data = df_features[unit_mask]\n",
    "        \n",
    "        for sensor in sensor_cols:\n",
    "            # Moyenne mobile\n",
    "            df_features.loc[unit_mask, f'{sensor}_ma'] = unit_data[sensor].rolling(\n",
    "                window=window_size, min_periods=1\n",
    "            ).mean()\n",
    "            \n",
    "            # Ã‰cart-type glissant\n",
    "            df_features.loc[unit_mask, f'{sensor}_std'] = unit_data[sensor].rolling(\n",
    "                window=window_size, min_periods=1\n",
    "            ).std()\n",
    "            \n",
    "            # DiffÃ©rence (taux de changement)\n",
    "            df_features.loc[unit_mask, f'{sensor}_delta'] = unit_data[sensor].diff().fillna(0)\n",
    "    \n",
    "    return df_features\n",
    "\n",
    "# Appliquer le feature engineering\n",
    "train_features = create_temporal_features(train_main_clean)\n",
    "test_features = create_temporal_features(test_main_clean)\n",
    "\n",
    "# Remplir les NaN crÃ©Ã©s par les opÃ©rations temporelles\n",
    "train_features = train_features.fillna(0)\n",
    "test_features = test_features.fillna(0)\n",
    "\n",
    "print(f\"\\nâœ… Features temporelles crÃ©Ã©es\")\n",
    "print(f\"   Nouvelles colonnes: {train_features.shape[1] - train_main_clean.shape[1]}\")\n",
    "print(f\"   Total de colonnes: {train_features.shape[1]}\")\n",
    "print(f\"   Format: sensor â†’ sensor_ma (moving avg), sensor_std (volatilitÃ©), sensor_delta (changement)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a475f84",
   "metadata": {},
   "source": [
    "## 3ï¸âƒ£ FEATURE ENGINEERING POUR SÃ‰RIES TEMPORELLES\n",
    "\n",
    "### Concept : Extraire du Signal du Bruit\n",
    "\n",
    "Pour chaque capteur, nous crÃ©ons des **features dÃ©rivÃ©es** qui capturent les tendances de dÃ©gradation :\n",
    "\n",
    "| Feature | Formule | InterprÃ©tation |\n",
    "|---------|---------|---|\n",
    "| **Moving Average** | Moyenne sur k cycles | Tendance lissÃ©e |\n",
    "| **Rolling Std** | Ã‰cart-type sur k cycles | VolatilitÃ©/instabilitÃ© |\n",
    "| **Delta** | DiffÃ©rence entre cycles | Taux de changement |\n",
    "\n",
    "Ces features enrichissent les capteurs bruts et amÃ©liorent la prÃ©diction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07cc0e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PrÃ©paration et nettoyage des donnÃ©es\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"Ã‰TAPE 2 : PRÃ‰PARATION ET NETTOYAGE\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# 1ï¸âƒ£ DÃ‰TECTION ET SUPPRESSION DE COLONNES CONSTANTES\n",
    "print(\"\\nğŸ“Š 1ï¸âƒ£ VÃ©rification de la variance des colonnes\")\n",
    "\n",
    "sensor_cols = [col for col in train_main.columns if col.startswith('sensor')]\n",
    "print(f\"   Colonnes capteurs: {len(sensor_cols)}\")\n",
    "\n",
    "constant_cols = [col for col in sensor_cols if train_main[col].nunique() <= 1]\n",
    "if constant_cols:\n",
    "    print(f\"   âš ï¸ Colonnes constantes dÃ©tectÃ©es: {constant_cols}\")\n",
    "    train_main = train_main.drop(columns=constant_cols)\n",
    "else:\n",
    "    print(f\"   âœ… Toutes les colonnes ont de la variance\")\n",
    "\n",
    "# 2ï¸âƒ£ NORMALISATION DES CAPTEURS (MinMax Scaling [0-1])\n",
    "print(f\"\\nğŸ“ˆ 2ï¸âƒ£ Normalisation des capteurs (MinMax Scaler)\")\n",
    "\n",
    "sensor_cols = [col for col in train_main.columns if col.startswith('sensor')]\n",
    "print(f\"   Normalisation de {len(sensor_cols)} capteurs...\")\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "train_main[sensor_cols] = scaler.fit_transform(train_main[sensor_cols])\n",
    "\n",
    "print(f\"   âœ… Range normalisÃ©: [0, 1]\")\n",
    "print(f\"      Exemple (sensor2): min={train_main['sensor2'].min():.4f}, max={train_main['sensor2'].max():.4f}\")\n",
    "\n",
    "# 3ï¸âƒ£ CRÃ‰ATION DE LA VARIABLE RUL (Remaining Useful Life)\n",
    "print(f\"\\nğŸ¯ 3ï¸âƒ£ CrÃ©ation de la variable cible RUL\")\n",
    "\n",
    "# Pour les donnÃ©es d'entraÃ®nement: RUL = max_cycle - cycle_actuel\n",
    "max_cycle_per_unit = train_main.groupby('unit')['cycle'].max()\n",
    "train_main['RUL'] = train_main.apply(\n",
    "    lambda row: max_cycle_per_unit[row['unit']] - row['cycle'],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Pour les donnÃ©es de test: ajouter les RUL rÃ©els\n",
    "test_main['RUL'] = rul_main.values\n",
    "\n",
    "print(f\"   âœ… RUL calculÃ© pour tous les enregistrements\")\n",
    "print(f\"      RUL moyen: {train_main['RUL'].mean():.1f} cycles\")\n",
    "print(f\"      RUL min: {train_main['RUL'].min():.0f} cycles, max: {train_main['RUL'].max():.0f} cycles\")\n",
    "print(f\"      Distribution: {train_main['RUL'].describe().to_dict()}\")\n",
    "\n",
    "# PrÃ©parer les donnÃ©es pour la modÃ©lisation\n",
    "train_main_clean = train_main.copy()\n",
    "test_main_clean = test_main.copy()\n",
    "\n",
    "print(\"\\nâœ… DonnÃ©es prÃ©parÃ©es et nettoyÃ©es\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77cbcbc",
   "metadata": {},
   "source": [
    "## 2ï¸âƒ£ PRÃ‰PARATION ET NETTOYAGE DES DONNÃ‰ES\n",
    "\n",
    "### Objectives\n",
    "- Identifier et Ã©liminer les colonnes non informatives\n",
    "- Normaliser les donnÃ©es pour amÃ©liorer la comparabilitÃ©\n",
    "- CrÃ©er la variable cible RUL (Remaining Useful Life)\n",
    "- PrÃ©parer les donnÃ©es pour la modÃ©lisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "510e9b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploration initiale des donnÃ©es\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"EXPLORATION INITIALE - STRUCTURE DES DONNÃ‰ES\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(f\"\\n1ï¸âƒ£ APERÃ‡U STRUCTUREL\")\n",
    "print(f\"   Nombre de moteurs: {train_main['unit'].max()} moteurs numÃ©rotÃ©s 1 Ã  {train_main['unit'].max()}\")\n",
    "print(f\"   Nombre de cycles par moteur:\")\n",
    "cycles_stats = train_main.groupby('unit')['cycle'].count()\n",
    "print(f\"     - Min: {cycles_stats.min()} cycles\")\n",
    "print(f\"     - Moyen: {cycles_stats.mean():.0f} cycles\")\n",
    "print(f\"     - Max: {cycles_stats.max()} cycles\")\n",
    "\n",
    "print(f\"\\n2ï¸âƒ£ COLONNES DISPONIBLES\")\n",
    "print(f\"   Total: {train_main.shape[1]} colonnes\")\n",
    "print(f\"   - Identifiants: unit, cycle\")\n",
    "print(f\"   - Conditions opÃ©rationnelles: setting1, setting2, setting3\")\n",
    "print(f\"   - Capteurs: {[col for col in train_main.columns if col.startswith('sensor')]}\")\n",
    "\n",
    "print(f\"\\n3ï¸âƒ£ VALEURS MANQUANTES\")\n",
    "missing = train_main.isnull().sum().sum()\n",
    "print(f\"   âœ“ DonnÃ©es complÃ¨tes: {missing == 0}\")\n",
    "\n",
    "print(f\"\\n4ï¸âƒ£ STATISTIQUES DESCRIPTIVES (aperÃ§u)\")\n",
    "stats = train_main.describe()\n",
    "print(f\"   Capteur 2:  mean={stats.loc['mean', 'sensor2']:.4f}, std={stats.loc['std', 'sensor2']:.4f}\")\n",
    "print(f\"   Capteur 7:  mean={stats.loc['mean', 'sensor7']:.4f}, std={stats.loc['std', 'sensor7']:.4f}\")\n",
    "print(f\"   Capteur 15: mean={stats.loc['mean', 'sensor15']:.4f}, std={stats.loc['std', 'sensor15']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e927cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chemins d'accÃ¨s aux fichiers\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# DÃ©terminer le rÃ©pertoire du dataset\n",
    "dataset_path = Path('./dataset')\n",
    "\n",
    "# Noms des colonnes selon la documentation NASA\n",
    "column_names = ['unit', 'cycle', 'setting1', 'setting2', 'setting3'] + [f'sensor{i}' for i in range(1, 22)]\n",
    "\n",
    "def load_dataset(dataset_name):\n",
    "    \"\"\"\n",
    "    Charge les donnÃ©es d'entraÃ®nement, test et RUL d'un dataset C-MAPSS\n",
    "    \n",
    "    ParamÃ¨tres:\n",
    "    -----------\n",
    "    dataset_name : str\n",
    "        Nom du dataset (FD001, FD002, FD003 ou FD004)\n",
    "    \n",
    "    Retour:\n",
    "    -------\n",
    "    tuple : (train_df, test_df, rul_df)\n",
    "    \"\"\"\n",
    "    train_file = dataset_path / f'train_{dataset_name}.txt'\n",
    "    test_file = dataset_path / f'test_{dataset_name}.txt'\n",
    "    rul_file = dataset_path / f'RUL_{dataset_name}.txt'\n",
    "    \n",
    "    # Charger les donnÃ©es\n",
    "    train = pd.read_csv(train_file, sep='\\s+', header=None, names=column_names)\n",
    "    test = pd.read_csv(test_file, sep='\\s+', header=None, names=column_names)\n",
    "    \n",
    "    # Charger les RUL rÃ©els\n",
    "    rul = pd.read_csv(rul_file, header=None, names=['RUL_real'])\n",
    "    \n",
    "    return train, test, rul\n",
    "\n",
    "# Charger tous les datasets\n",
    "print(\"\\nğŸ“¦ Chargement des 4 datasets C-MAPSS...\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "datasets = ['FD001', 'FD002', 'FD003', 'FD004']\n",
    "data = {}\n",
    "\n",
    "for dataset in datasets:\n",
    "    train, test, rul = load_dataset(dataset)\n",
    "    data[dataset] = {'train': train, 'test': test, 'rul': rul}\n",
    "    print(f\"âœ“ {dataset:6s} | Train: {train.shape[0]:5d} rows | Test: {test.shape[0]:5d} rows | Moteurs: {train['unit'].max():3.0f}\")\n",
    "\n",
    "# Utiliser FD001 pour l'analyse principale (conditions simples, 1 mode de dÃ©gradation)\n",
    "train_main = data['FD001']['train'].copy()\n",
    "test_main = data['FD001']['test'].copy()\n",
    "rul_main = data['FD001']['rul'].copy()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"SÃ‰LECTION DU DATASET PRINCIPAL : FD001\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"âœ“ Configuration : Conditions Sea Level (simples)\")\n",
    "print(f\"âœ“ Mode de dÃ©gradation : 1 (HPC Degradation)\")\n",
    "print(f\"âœ“ DonnÃ©es entraÃ®nement : {train_main.shape[0]:,d} enregistrements\")\n",
    "print(f\"âœ“ DonnÃ©es test : {test_main.shape[0]:,d} enregistrements\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5048f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# 1ï¸âƒ£ IMPORTATION DES BIBLIOTHÃˆQUES ESSENTIELLES\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"Ã‰TAPE 1 : CHARGEMENT ET CONFIGURATION DE L'ENVIRONNEMENT\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuration des styles\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"\\nâœ… BibliothÃ¨ques chargÃ©es avec succÃ¨s\")\n",
    "print(\"   ğŸ“¦ Pandas & NumPy pour la manipulation de donnÃ©es\")\n",
    "print(\"   ğŸ“Š Matplotlib & Seaborn pour les visualisations statiques\")\n",
    "print(\"   ğŸ“ˆ Plotly pour les dashboards interactifs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e09d3cf5",
   "metadata": {},
   "source": [
    "# ğŸš€ Dashboard Intelligent pour l'Optimisation de la Maintenance PrÃ©dictive\n",
    "## Industrie AÃ©ronautique - NASA Turbofan Engine Degradation Dataset\n",
    "\n",
    "### ğŸ¯ Objectif du Projet\n",
    "CrÃ©er un systÃ¨me de maintenance prÃ©dictive pour optimiser les coÃ»ts et rÃ©duire les temps d'arrÃªt non planifiÃ©s dans une flotte de 150 turbofans.\n",
    "\n",
    "### ğŸ“Š Dataset UtilisÃ©\n",
    "**NASA C-MAPSS** (Commercial Modular Aero-Propulsion System Simulation)\n",
    "- **Moteurs** : ~100 moteurs avec cycles de dÃ©gradation complets\n",
    "- **Capteurs** : 21 capteurs mesurant tempÃ©rature, pression, vibrations, etc.\n",
    "- **Format** : SÃ©ries temporelles multivariÃ©es de l'Ã©tat neuf jusqu'Ã  la panne\n",
    "- **ScÃ©narios** : 4 configurations (FD001-FD004) avec conditions et dÃ©faillances diffÃ©rentes\n",
    "\n",
    "### ğŸ“ CompÃ©tences PÃ©dagogiques Couvertes\n",
    "âœ“ Analyse exploratoire avancÃ©e (EDA) avec dÃ©tection d'anomalies  \n",
    "âœ“ Feature engineering pour sÃ©ries temporelles  \n",
    "âœ“ Clustering et segmentation des profils de dÃ©gradation  \n",
    "âœ“ PrÃ©diction du RUL (Remaining Useful Life) - RÃ©gression  \n",
    "âœ“ SystÃ¨me d'alerte intelligent - Classification  \n",
    "âœ“ Visualisations interactives avec Plotly  \n",
    "âœ“ Storytelling data pour dÃ©cision business"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
